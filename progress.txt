## Codebase Patterns
- FastAPI CSV export pattern: Use StreamingResponse with StringIO, csv.writer, and Content-Disposition header
- FastAPI PDF export pattern: Use StreamingResponse with BytesIO, ReportLab SimpleDocTemplate, and list[Flowable] for elements
- Authentication via CurrentUser dependency from app.core.deps
- Backend quality checks: `docker exec opm-backend uv run mypy src/` and `docker exec opm-backend uv run ruff check src/`
- Endpoint pattern: fetch model with relationships → return 404 if not found → process data → return response
- For reportlab: Install both reportlab package and types-reportlab for type stubs

---

## 2026-01-27 - US-001
- Implemented GET /api/scans/{scan_id}/export/csv endpoint
- Added CSV export functionality with proper headers (IP, Port, Protocol, Service, First Seen, Last Seen)
- Used FastAPI StreamingResponse with proper Content-Disposition header for file download
- Filename format: scan_{scan_id}_{timestamp}.csv

**Files changed:**
- backend/src/app/routers/scans.py

**Learnings for future iterations:**
- FastAPI pattern for CSV exports: Use StreamingResponse with StringIO and csv.writer
- Authentication is handled via CurrentUser dependency (from app.core.deps)
- Use datetime.now(timezone.utc).strftime() for timestamp formatting in filenames
- CSV data should use .isoformat() for datetime serialization
- Quality checks: Run `docker exec opm-backend uv run mypy src/` and `docker exec opm-backend uv run ruff check src/`
- The backend uses FastAPI with async SQLAlchemy, all endpoints should be async
- Service layer functions (in app/services/) handle database operations
- Endpoint pattern: get model with relationships, return 404 if not found, process data, return response
---

## 2026-01-27 - US-002
- Implemented GET /api/alerts/export/csv endpoint
- Added CSV export functionality with proper headers (Alert Type, IP, Port, Network, Status, Created At)
- Supports optional query params: alert_type (alias "type") and acknowledged for filtering
- Uses FastAPI StreamingResponse with proper Content-Disposition header for file download
- Filename format: alerts_{timestamp}.csv

**Files changed:**
- backend/src/app/routers/alerts.py

**Learnings for future iterations:**
- Alert model doesn't have an `acknowledged_at` field, only an `acknowledged` boolean
- The CSV export uses the same pattern as scans: csv.writer with StringIO
- Query parameter alias "type" is used for alert_type to match existing API patterns
- For exports, use a large limit (10000) instead of pagination to get all records
- The alerts_service.get_alerts() returns tuples of (alert, network_name) for each alert
---

## 2026-01-27 - US-003
- Implemented GET /api/hosts/export/csv endpoint
- Added CSV export functionality with proper headers (IP, Hostname, Status, OS Guess, First Seen, Last Seen, Open Ports Count)
- Supports optional query params: network_id and is_pingable (aliased as "status") for filtering
- Uses FastAPI StreamingResponse with proper Content-Disposition header for file download
- Filename format: hosts_{timestamp}.csv
- Status field derived from is_pingable: null = "Unknown", true = "Up", false = "Down"

**Files changed:**
- backend/src/app/routers/hosts.py

**Learnings for future iterations:**
- Host model doesn't have an OS guess field, so it's left empty in the CSV export
- The is_pingable field can be null, true, or false - need to handle all three cases
- For hosts export, need to fetch open port count for each host individually using hosts_service.get_open_port_count_for_host()
- The query parameter alias can be used to provide alternative names (e.g., "status" maps to is_pingable)
- Pre-existing mypy errors in hosts service are not related to new router code
---

## 2026-01-27 - US-004
- Implemented GET /api/scans/{scan_id}/export/pdf endpoint
- Installed reportlab library (version 4.4.9) for PDF generation
- PDF includes scan metadata (network name, scan date, status, completion date)
- PDF includes summary statistics showing total open ports found
- PDF includes detailed table of open ports with headers: IP, Port, Protocol, Service, First Seen, Last Seen
- Filename format: scan_{scan_id}_{timestamp}.pdf
- Used ReportLab's SimpleDocTemplate, Paragraph, Table, and TableStyle for PDF generation

**Files changed:**
- backend/src/app/routers/scans.py
- backend/pyproject.toml

**Learnings for future iterations:**
- FastAPI PDF export pattern: Use StreamingResponse with BytesIO (not StringIO like CSV)
- ReportLab requires type annotations: use `list[Flowable]` for elements list to pass mypy strict mode
- Install both `reportlab` package AND `types-reportlab` for type stubs to pass mypy checks
- ReportLab uses inch units from reportlab.lib.units for sizing
- Table styling uses TableStyle with tuples like ('BACKGROUND', (0, 0), (-1, 0), colors.grey)
- For long lines that exceed 100 chars (ruff E501), extract variables or use parentheses for multi-line expressions
- PDF generation uses same authentication pattern (CurrentUser) and error handling (404) as CSV exports
- The `doc.build(elements)` method writes to the BytesIO buffer, then get content with buffer.getvalue()
---
## 2026-01-27 - US-005
- Implemented GET /api/alerts/export/pdf endpoint
- PDF includes report header with generation timestamp
- PDF includes summary statistics: total alerts, open/acknowledged counts, breakdown by alert type
- PDF includes detailed table of alerts with columns: Alert Type, IP, Port, Network, Status, Created At
- Supports optional query params: alert_type (alias "type") and acknowledged for filtering
- Filename format: alerts_{timestamp}.pdf
- Used ReportLab's SimpleDocTemplate, Paragraph, Table, and TableStyle for PDF generation

**Files changed:**
- backend/src/app/routers/alerts.py

**Learnings for future iterations:**
- When generating PDF reports for list-based data (not single-item reports), calculate summary statistics before building PDF elements
- Group-by operations in Python can be done efficiently with simple dict accumulation: `by_type[key] = by_type.get(key, 0) + 1`
- Paragraph elements support HTML-like tags for formatting (e.g., `<b>`, `<br/>`)
- For alerts PDF export, use same filter pattern as CSV export: get all alerts with large limit (10000) instead of pagination
- The alerts_service.get_alerts() returns tuples of (alert, network_name), which is different from other services that return models directly
- Pre-existing mypy errors in other files (e.g., alerts.py line 514 in bulk_whitelist_network) are not blockers for new code that passes type checks
---

## 2026-01-27 - US-006
- Implemented GET /api/hosts/export/pdf endpoint
- PDF includes report header with generation timestamp
- PDF includes summary statistics: total hosts, breakdown by status (Up/Down/Unknown)
- PDF includes detailed table of hosts with columns: IP, Hostname, Status, First Seen, Last Seen, Open Ports
- Supports optional query params: network_id and is_pingable (aliased as "status") for filtering
- Filename format: hosts_{timestamp}.pdf
- Used ReportLab's SimpleDocTemplate, Paragraph, Table, and TableStyle for PDF generation

**Files changed:**
- backend/src/app/routers/hosts.py

**Learnings for future iterations:**
- When using long list literals that exceed line length (E501), extract them to a variable first
- For hosts PDF export, use same filter pattern as CSV export and reuse status calculation logic
- The status field is derived from is_pingable: null = "Unknown", true = "Up", false = "Down"
- For each host, need to fetch open port count using hosts_service.get_open_port_count_for_host()
- Pre-existing mypy errors in services layer (e.g., hosts.py) are not blockers for new router code
---

## 2026-01-27 - US-007
- Implemented Export dropdown button on ScanDetail page
- Added dropdown with "Export as CSV" and "Export as PDF" options
- Positioned next to "Back to scans" button in the header
- Implemented handleExportCsv and handleExportPdf functions using fetch API with blob download pattern
- Added loading state ("Exporting...") during export operations
- Added toast notification system with auto-dismiss after 3 seconds
- Toast shows success/error messages for export operations
- Dropdown closes automatically when export is triggered

**Files changed:**
- frontend/src/pages/ScanDetail.tsx

**Learnings for future iterations:**
- Frontend export pattern: Use fetch with getAuthHeaders, convert response to blob, create object URL, trigger download with createElement('a'), then revoke URL
- Toast notification pattern: useState for toast state, useEffect with setTimeout for auto-dismiss after 3 seconds
- Dropdown pattern: useState for visibility, position with "absolute right-0 top-full z-20 mt-2" classes
- Loading states: Show "Exporting..." text and disable button during async operations
- Timestamp format for filenames: new Date().toISOString().replace(/[:.]/g, '-').slice(0, 19)
- Import API_BASE_URL and getAuthHeaders from '../lib/api' for authenticated fetch calls
- Toast styling uses fixed positioning (top-8 right-8) with z-[100] to appear above all content
---

## 2026-01-27 - US-008
- Implemented Export dropdown button on RiskOverview page
- Added dropdown with "Export as CSV" and "Export as PDF" options
- Positioned next to "Resolve" button in the header area
- Implemented handleExportCsv and handleExportPdf functions using fetch API with blob download pattern
- Added loading state ("Exporting...") during export operations
- Integrated with existing toast notification system for success/error messages
- Export functions respect current filters (severity and status filters)
- Dropdown closes automatically when export is triggered
- Typecheck passes

**Files changed:**
- frontend/src/pages/RiskOverview.tsx

**Learnings for future iterations:**
- Export dropdown follows same pattern as ScanDetail page (US-007)
- RiskOverview page has more complex filter state (severityFilter, statusFilter, networkFilter, searchQuery)
- When exporting with filters, map UI filter states to API query params (e.g., statusFilter='pending' → acknowledged=false)
- The statusFilter has multiple values ('all', 'blocked', 'pending', 'approved', 'monitoring') but only 'pending' and 'monitoring' map to acknowledged param
- Positioned Export button after Resolve button and before Policy/Back to dashboard links
- Toast notification state already exists in RiskOverview (reused existing implementation)
- Browser testing requires valid authentication credentials - manual testing recommended for full verification
---

## 2026-01-27 - US-009
- Implemented Export dropdown button on Hosts page
- Added dropdown with "Export as CSV" and "Export as PDF" options
- Positioned before admin-only controls (network selection and discovery button) in header
- Implemented handleExportCsv and handleExportPdf functions using fetch API with blob download pattern
- Export functions respect current filters: network_id and pingable status filters
- Filter mapping: pingableFilter='yes' → status=true, pingableFilter='no' → status=false
- Added loading state ("Exporting...") during export operations
- Reused existing toast notification system for success/error messages
- Dropdown closes automatically when export is triggered
- Typecheck passes

**Files changed:**
- frontend/src/pages/Hosts.tsx

**Learnings for future iterations:**
- Export dropdown follows same pattern as ScanDetail (US-007) and RiskOverview (US-008) pages
- Hosts page has simpler filter state compared to RiskOverview (networkFilter and pingableFilter)
- Filter parameter name mapping: pingableFilter uses 'status' query param (not 'is_pingable') for the export endpoints
- Positioned Export button to be accessible to all users (not just admins), placed before admin-specific discovery controls
- Toast notification state already exists in Hosts page (reused existing implementation like other pages)
- Export dropdown should be visible to all authenticated users, not just admins, for reporting purposes
---

## 2026-01-27 - US-010
- Implemented GET /api/trends/open-ports endpoint for historical open port trend data
- Created trends router at backend/src/app/routers/trends.py with PeriodType enum (day/week/month)
- Created trends schema at backend/src/app/schemas/trends.py with TrendDataPoint and TrendDataResponse models
- Endpoint aggregates unique ip:port combinations by time period using SQLAlchemy func.date, func.date_sub, func.concat
- Supports filtering by network_id, date range (start_date, end_date), and time period grouping
- Returns JSON array with {date, count} objects sorted by date ascending
- Registered trends router in main.py
- Typecheck and ruff checks pass

**Files changed:**
- backend/src/app/routers/trends.py (new)
- backend/src/app/schemas/trends.py (new)
- backend/src/app/main.py

**Learnings for future iterations:**
- SQL date aggregation pattern for MySQL: Use func.date() for daily, func.date_sub() with func.weekday() for weekly, func.concat() for monthly
- Trend endpoints follow pattern: Accept date range + period + optional filters → aggregate data with GROUP BY → return sorted data points
- Count distinct combinations using func.count(distinct(func.concat(field1, ":", field2)))
- Join Scan table when filtering by network_id since open_ports doesn't have direct network_id column
- Enum pattern for period types: Use str, Enum with values DAY/WEEK/MONTH for FastAPI query params
- Empty array is returned when no data matches the filter criteria (no special handling needed)
- Pre-existing mypy errors in other services (hosts.py, policy.py, etc.) are not blockers for new code
---

## 2026-01-27 - US-011
- Implemented GET /api/trends/hosts endpoint for historical host discovery trend data
- Endpoint aggregates hosts by first_seen_at grouped by time period (day/week/month)
- Supports filtering by network_id and date range (start_date, end_date)
- Returns JSON array with {date, count} objects sorted by date ascending
- Used same SQL date aggregation pattern as open-ports endpoint (func.date, func.date_sub, func.concat)
- Network filtering uses func.json_contains to check if network_id is in seen_by_networks JSON array
- Typecheck and ruff checks pass

**Files changed:**
- backend/src/app/routers/trends.py

**Learnings for future iterations:**
- Hosts model stores network associations in seen_by_networks JSON array field (not a foreign key)
- Network filtering for hosts requires func.json_contains(Host.seen_by_networks, str(network_id))
- Trend aggregation pattern reused from US-010: date truncation logic based on period type
- Hosts are counted by Host.id (simple count), not distinct combinations like open ports
- Same PeriodType enum and TrendDataPoint/TrendDataResponse schemas work for all trend endpoints
---

## 2026-01-27 - US-012
- Implemented GET /api/trends/alerts endpoint for historical alert trend data
- Created AlertTrendDataPoint schema with date, count, and acknowledged_count fields
- Created AlertTrendDataResponse schema for API response
- Endpoint aggregates alerts by created_at grouped by time period (day/week/month)
- Supports filtering by network_id and alert_type
- Used SQL func.if_() to calculate acknowledged_count: sum(if(acknowledged, 1, 0))
- Returns JSON array with {date, count, acknowledged_count} objects sorted by date ascending
- Typecheck and ruff checks pass

**Files changed:**
- backend/src/app/routers/trends.py
- backend/src/app/schemas/trends.py

**Learnings for future iterations:**
- For aggregating boolean fields, use func.sum(func.if_(field, 1, 0)) pattern to get counts
- When trend data needs additional metrics beyond count, create separate schema models (e.g., AlertTrendDataPoint vs TrendDataPoint)
- Alert model has network_id and alert_type fields for direct filtering (no joins needed)
- SQL conditional aggregation pattern: func.if_(condition, true_value, false_value) works in MySQL
- Reused same PeriodType enum and date truncation logic from previous trend endpoints
- Coalesce null acknowledged_count with `or 0` to ensure integer return type
---

## 2026-01-27 - US-013
- Implemented TrendChart component for displaying historical trend data
- Installed recharts library (version 4.2.0) for line chart visualization
- Created reusable component that accepts data array and chart config props
- Component renders responsive line chart with time-based x-axis and count-based y-axis
- Implemented loading state with spinner animation
- Implemented empty state with "No data available" message
- Implemented error state with error message display
- Styled component with TailwindCSS matching theme (dark mode support)
- Added CSS variables for tooltip colors in both light and dark modes
- Chart supports single or dual line rendering (e.g., total count + acknowledged count)
- Typecheck passes

**Files changed:**
- frontend/src/components/TrendChart.tsx (new)
- frontend/package.json
- frontend/package-lock.json
- frontend/src/index.css

**Learnings for future iterations:**
- Recharts library pattern: Use ResponsiveContainer with LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, and Legend components
- TrendChart accepts generic data array with date/count fields and a config object for customization
- Config includes: title, dataKey (for primary line), optional dataKey2 (for secondary line), colors, and axis labels
- Loading/empty/error states are essential for good UX when fetching async data
- CSS variables for tooltip styling: --tooltip-bg, --tooltip-border, --tooltip-text ensure proper dark mode support
- Recharts Tooltip contentStyle accepts CSS variables via var() for theme-aware styling
- Line component name prop can format dataKey with proper capitalization for legend display
- ResponsiveContainer with 100% width and fixed height (300px) provides good chart sizing
---

## 2026-01-27 - US-014
- Implemented Trends page with historical visualizations
- Created new Trends page component at frontend/src/pages/Trends.tsx with route /trends
- Added "Trends" navigation link to main menu in App.tsx between "Risk Overview" and "Policy"
- Added route to router configuration in main.tsx
- Implemented time period selector with options: Last 7 days, Last 30 days, Last 90 days (default: 30 days)
- Implemented network filter dropdown showing all networks or specific network selection
- Added three trend charts using TrendChart component: Open Ports Over Time, Hosts Discovered Over Time, Alerts Over Time
- Charts update automatically when filters change using React Query
- Alerts chart displays two lines: total count (red) and acknowledged count (orange)
- Verified in browser: all charts display correctly with proper styling and responsive layout
- Typecheck passes

**Files changed:**
- frontend/src/pages/Trends.tsx (new)
- frontend/src/App.tsx
- frontend/src/main.tsx

**Learnings for future iterations:**
- Pages that use new npm dependencies (like recharts) require rebuilding the Docker frontend container: `docker compose -f compose-dev.yml up -d --build frontend`
- Date range calculation pattern: Use new Date() and setDate() to calculate start/end dates based on period
- React Query integration: Build query params dynamically with URLSearchParams and include all filter values in queryKey for proper cache invalidation
- Multiple trend queries can run in parallel using React Query - each chart has its own query with loading/error states
- TrendChart component (from US-013) supports both single and dual line charts via dataKey2 prop
- Filter state pattern: Use useState for filter values (period, networkId) and useMemo for derived values (dateRange)
- Browser testing with dev-browser: Admin credentials are admin@stylite.de / admin (from database, not the default admin@example.com)
---

## 2026-01-27 - US-015
- Implemented alert_comments table migration (revision 002)
- Created AlertComment SQLAlchemy model with relationships to Alert and User
- Added bidirectional relationships: Alert.comments and User.alert_comments
- Migration includes CASCADE delete on alert_id foreign key to automatically clean up comments when alerts are deleted
- Migration ran successfully and database is at revision 002 (head)
- Typecheck and ruff checks pass for all new/modified files

**Files changed:**
- backend/src/migrations/versions/002_add_alert_comments.py (new)
- backend/src/app/models/alert_comment.py (new)
- backend/src/app/models/alert.py (added comments relationship)
- backend/src/app/models/user.py (added alert_comments relationship)
- backend/src/app/models/__init__.py (exported AlertComment model)

**Learnings for future iterations:**
- Migration pattern: Use ondelete="CASCADE" for foreign keys when child records should be deleted with parent
- Model relationships: Use cascade="all, delete-orphan" on parent side for bidirectional one-to-many relationships
- Updated_at pattern: Use server_default and onupdate with func.now() for automatic timestamp updates
- When adding relationships to existing models, import new model in TYPE_CHECKING block to avoid circular imports
- Migration revision numbering: Use simple sequential numbers (001, 002, etc.) with down_revision pointing to previous
- Quality checks pattern: Run mypy and ruff on specific new/modified files to verify no new errors introduced
- Pre-existing mypy errors in other files (hosts.py, policy.py, alerts.py, etc.) are not blockers for new code
---
